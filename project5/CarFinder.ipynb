{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.externals import joblib\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline  \n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CFClassifier:\n",
    "    def __init__(self, unpickle=False):\n",
    "        \n",
    "        self.file_name = \"CFClassifier.pkl\"\n",
    "        \n",
    "        if unpickle == True:\n",
    "            with open(self.file_name, 'rb') as file:\n",
    "                items = pickle.load(file)\n",
    "                self.pix_per_cell = items[\"pix_per_cell\"]\n",
    "                self.cell_per_block = items[\"cell_per_block\"]\n",
    "                self.orient = items[\"orient\"]\n",
    "                self.hog_channel = items[\"hog_channel\"]\n",
    "                self.spatial_size = items[\"spatial_size\"]\n",
    "                self.nbins = items[\"nbins\"]\n",
    "                self.scaler = items[\"scaler\"]\n",
    "                self.svc = items[\"svc\"]\n",
    "        else:\n",
    "            self.pix_per_cell = 8\n",
    "            self.cell_per_block = 2\n",
    "            self.orient = 9\n",
    "            self.hog_channel = \"ALL\"\n",
    "            self.spatial_size = (32, 32)\n",
    "            self.nbins = 32\n",
    "            self.scaler = None\n",
    "            self.svc = None\n",
    "        \n",
    "\n",
    "    def train(self, training_images, visualise=False):\n",
    "\n",
    "        features_car = self.__process_images(training_images[0], visualise=visualise)\n",
    "        print(len(features_car))\n",
    "        features_non_car = self.__process_images(training_images[1], visualise=visualise)\n",
    "        print(len(features_non_car))\n",
    "        \n",
    "        X = np.vstack((features_car, features_non_car)).astype(np.float64) \n",
    "        print(X.shape)\n",
    "        y = np.hstack((np.ones(len(features_car)), np.zeros(len(features_non_car))))\n",
    "\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(X)\n",
    "        scaledX = self.scaler.transform(X)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(scaledX, y, \n",
    "                                                            test_size=0.2, \n",
    "                                                            random_state=np.random.randint(0, 100))   \n",
    "        \n",
    "        self.svc = LinearSVC()\n",
    "        self.svc.fit(X_train, y_train)\n",
    "        score = round(self.svc.score(X_test, y_test), 4)\n",
    "        \n",
    "        with open(self.file_name, 'wb') as file:            \n",
    "            items = {\n",
    "                \"pix_per_cell\" : self.pix_per_cell,\n",
    "                \"cell_per_block\": self.cell_per_block,\n",
    "                \"orient\": self.orient,\n",
    "                \"hog_channel\": self.hog_channel,\n",
    "                \"spatial_size\": self.spatial_size,\n",
    "                \"nbins\": self.nbins,\n",
    "                \"scaler\": self.scaler,\n",
    "                \"svc\": self.svc\n",
    "            }\n",
    "            pickle.dump(items, file)\n",
    "        \n",
    "        return score\n",
    "        \n",
    "    \n",
    "    def test(self, test_images, test_labels):\n",
    "        if self.svc == None:\n",
    "            raise ValueError('Classifier is not initialized or ready')\n",
    "        \n",
    "        features = self.__process_images(test_images)\n",
    "        scaledX = self.scaler.transform(features)        \n",
    "        score = round(self.svc.score(scaledX, test_labels), 4)\n",
    "        return score\n",
    "\n",
    "    \n",
    "    def predict(self, img, visualise=False):\n",
    "        if self.svc == None:\n",
    "            raise ValueError('Classifier is not initialized or ready')\n",
    "                \n",
    "        features = self.process_image(img, visualise=visualise)\n",
    "        scaledX = self.scaler.transform(features.reshape(1, -1))        \n",
    "        return self.svc.predict(scaledX)\n",
    "    \n",
    "    def process_image(self, img, visualise=False):\n",
    "\n",
    "        # - Get spatial features\n",
    "        spatial_features = self.get_spatial_features(img, size=self.spatial_size)\n",
    "#         if visualise == True:\n",
    "#             plt.subplot(1,5,4).plot(spatial_features)\n",
    "\n",
    "        # - Get Hist features\n",
    "        hist_features = self.get_colorhist_features(img, nbins=self.nbins)  \n",
    "#         if visualise == True:\n",
    "#             plt.subplot(1,5,5).plot(hist_features)\n",
    "\n",
    "        # - Get HOG features\n",
    "        hog_features = []        \n",
    "        if self.hog_channel == \"ALL\":\n",
    "            for channel in range(img.shape[2]):\n",
    "                channel_hog_features, hog_image = self.get_hog_features(img[:,:,channel], \n",
    "                                                                   self.orient,\n",
    "                                                                   self.pix_per_cell,\n",
    "                                                                   self.cell_per_block,\n",
    "                                                                   vis = visualise)                                \n",
    "                hog_features.append(channel_hog_features)\n",
    "\n",
    "                if visualise == True:\n",
    "                    plt.subplot(1,5,channel+1).imshow(hog_image, cmap=\"gray\")\n",
    "        else:\n",
    "            channel_hog_features, hog_image = self.get_hog_features(img[:,:,self.hog_channel], \n",
    "                                                               self.orient,\n",
    "                                                               self.pix_per_cell,\n",
    "                                                               self.cell_per_block,\n",
    "                                                               vis = visualise)                                \n",
    "            hog_features.append(channel_hog_features)\n",
    "\n",
    "            if visualise == True:\n",
    "                plt.subplot(1,5,1).imshow(hog_image, cmap=\"gray\")\n",
    "            \n",
    "        \n",
    "        hog_features = np.ravel(hog_features)\n",
    "\n",
    "        return np.hstack((spatial_features, hist_features, hog_features))\n",
    "        \n",
    "    # ---------------------------------------------------------------------------\n",
    "    # Private methods\n",
    "    # ---------------------------------------------------------------------------\n",
    "    def __process_images(self, images, visualise = False):\n",
    "        \n",
    "        all_features = []\n",
    "        for file in tqdm(images):            \n",
    "            img = cv2.imread(file)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)            \n",
    "            img = img.astype(np.float32)/255\n",
    "            features = self.process_image(img, visualise=visualise)   \n",
    "            all_features.append(features)\n",
    "            \n",
    "        return all_features\n",
    "            \n",
    "\n",
    "    def get_spatial_features(self, img, size=(32, 32)):\n",
    "        color1 = cv2.resize(img[:,:,0], size).ravel()\n",
    "        color2 = cv2.resize(img[:,:,1], size).ravel()\n",
    "        color3 = cv2.resize(img[:,:,2], size).ravel()\n",
    "        return np.hstack((color1, color2, color3))\n",
    "                       \n",
    "\n",
    "    def get_colorhist_features(self, img, nbins=32):\n",
    "        channel1_hist = np.histogram(img[:,:,0], bins=nbins)\n",
    "        channel2_hist = np.histogram(img[:,:,1], bins=nbins)\n",
    "        channel3_hist = np.histogram(img[:,:,2], bins=nbins)\n",
    "        \n",
    "        hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))        \n",
    "        return hist_features    \n",
    "    \n",
    "    \n",
    "    def get_hog_features(self, img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=False):\n",
    "        hog_image = None\n",
    "            \n",
    "        if vis == True:\n",
    "            features, hog_image = hog(img, orientations=orient, \n",
    "                                      pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                      cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                      transform_sqrt=True, \n",
    "                                      visualise=vis, feature_vector=feature_vec)\n",
    "        else:\n",
    "            features = hog(img, orientations=orient, \n",
    "                                      pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                      cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                      transform_sqrt=True, \n",
    "                                      visualise=vis, feature_vector=feature_vec)\n",
    "                    \n",
    "        return features, hog_image\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CFCarFinder:\n",
    "    def __init__(self, clf = None):\n",
    "        self.clf = clf\n",
    "    \n",
    "    def findcar(self, img, draw_boxes=False):\n",
    "        img_cpy = np.copy(img)\n",
    "        shape = img_cpy.shape\n",
    "        #img_cpy = cv2.resize(img_cpy, (np.int(shape[1]/1.5), np.int(shape[0]/1.5)))        \n",
    "        hot_windows = []\n",
    "        for w_size in range(64, 200, 64):\n",
    "            windows = self.__get_windows(img_cpy, y_start=img_cpy.shape[0]//2, y_stop=img_cpy.shape[0]-100, xy_overlap=0.25, size_wh=(w_size,w_size))\n",
    "            for window in windows:\n",
    "                window_image = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))\n",
    "                window_image = cv2.cvtColor(window_image, cv2.COLOR_RGB2YCrCb)\n",
    "                window_image = window_image.astype(np.float32)/255\n",
    "                if self.clf.predict(window_image) == 1.:\n",
    "                    hot_windows.append(window)\n",
    "\n",
    "        if draw_boxes == True:\n",
    "            for window in hot_windows:\n",
    "                cv2.rectangle(img_cpy, window[0], window[1], (0,255,0), thickness=5)\n",
    "            plt.imshow(img_cpy)\n",
    "    \n",
    "    def findcar_with_subsampling(self, img, scale=1.0):\n",
    "                \n",
    "        #make a copy\n",
    "        draw_img = np.copy(img)\n",
    "        \n",
    "        #scale to 0-1\n",
    "        img = img.astype(np.float32)/255\n",
    "        \n",
    "        ystart = img.shape[0]//2\n",
    "        ystop = img.shape[0]-100\n",
    "        \n",
    "        #half of the iamge\n",
    "        img_tosearch = img[ystart:ystop,:,:]        \n",
    "        ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2YCrCb)\n",
    "\n",
    "        if scale != 1:\n",
    "            imshape = ctrans_tosearch.shape\n",
    "            ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "            \n",
    "        ch1 = ctrans_tosearch[:,:,0]\n",
    "        ch2 = ctrans_tosearch[:,:,1]\n",
    "        ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "        # Define blocks and steps as above\n",
    "        nxblocks = (ch1.shape[1] // clf.pix_per_cell) - clf.cell_per_block + 1\n",
    "        nyblocks = (ch1.shape[0] // clf.pix_per_cell) - clf.cell_per_block + 1 \n",
    "        nfeat_per_block = clf.orient*clf.cell_per_block**2\n",
    "    \n",
    "        # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "        window = 64\n",
    "        nblocks_per_window = (window // clf.pix_per_cell) - clf.cell_per_block + 1\n",
    "        cells_per_step = 1  # Instead of overlap, define how many cells to step\n",
    "        nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "        nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "    \n",
    "        # Compute individual channel HOG features for the entire image        \n",
    "        hog1, hog_image = clf.get_hog_features(ch1, clf.orient, clf.pix_per_cell, clf.cell_per_block, feature_vec=False)\n",
    "        hog2, hog_image = clf.get_hog_features(ch2, clf.orient, clf.pix_per_cell, clf.cell_per_block, feature_vec=False)\n",
    "        hog3, hog_image = clf.get_hog_features(ch3, clf.orient, clf.pix_per_cell, clf.cell_per_block, feature_vec=False)\n",
    "    \n",
    "        hot_windows = []\n",
    "        \n",
    "        for xb in range(nxsteps):\n",
    "            for yb in range(nysteps):\n",
    "                ypos = yb*cells_per_step\n",
    "                xpos = xb*cells_per_step\n",
    "                \n",
    "                # Extract HOG for this patch\n",
    "                hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "                xleft = xpos*clf.pix_per_cell\n",
    "                ytop = ypos*clf.pix_per_cell\n",
    "\n",
    "                # Extract the image patch\n",
    "                subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "          \n",
    "                # Get color features\n",
    "                \n",
    "                spatial_features = clf.get_spatial_features(subimg, size=clf.spatial_size)                \n",
    "                hist_features = clf.get_colorhist_features(subimg, nbins=clf.nbins)\n",
    "\n",
    "                # Scale features and make a prediction\n",
    "                test_features = clf.scaler.transform(np.hstack((spatial_features, \n",
    "                                                                hist_features, hog_features)).reshape(1, -1))    \n",
    "                test_prediction = clf.svc.predict(test_features)\n",
    "            \n",
    "                if test_prediction == 1:\n",
    "                    xbox_left = np.int(xleft*scale)\n",
    "                    ytop_draw = np.int(ytop*scale)\n",
    "                    win_draw = np.int(window*scale)\n",
    "                    hot_windows.append([(xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart)])\n",
    "                    #cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart),(0,0,255),6)         \n",
    "\n",
    "        return hot_windows\n",
    "    \n",
    "    def get_labels(self, img, hot_windows, threshold=10):\n",
    "        heat = np.zeros_like(img[:,:,0]).astype(np.float)        \n",
    "        heat = self.add_heat(heat,hot_windows)            \n",
    "        heat = self.apply_threshold(heat,threshold)      \n",
    "        heatmap = np.clip(heat, 0, 255)                \n",
    "        return label(heatmap)\n",
    "        \n",
    "    def __get_windows(self, img, x_start = None, x_stop=None, y_start=None, y_stop=None, xy_overlap=0.5, size_wh=(200, 200)):\n",
    "        \n",
    "        windows =[]\n",
    "        #print(img.shape)\n",
    "        i_height, i_width, channels = img.shape\n",
    "        if x_start == None:\n",
    "            x_start = 0\n",
    "        \n",
    "        if y_start == None:\n",
    "            y_start = 0\n",
    "            \n",
    "        if x_stop == None:\n",
    "            x_stop = i_width - int(size_wh[0]*xy_overlap)\n",
    "        \n",
    "        if y_stop == None:\n",
    "            y_stop = i_height - int(size_wh[1]*xy_overlap)\n",
    "            \n",
    "        for x in range(x_start, x_stop, int(size_wh[0]*xy_overlap)):\n",
    "            for y in range (y_start, y_stop, int(size_wh[1]*xy_overlap)):\n",
    "                windows.append([(x, y),(x+size_wh[0], y+size_wh[1])])\n",
    "                \n",
    "        return windows\n",
    "        \n",
    "\n",
    "    def draw_labeles(self, img, labels):\n",
    "        # Iterate through all detected cars\n",
    "        for car_number in range(1, labels[1]+1):\n",
    "            # Find pixels with each car_number label value\n",
    "            nonzero = (labels[0] == car_number).nonzero()\n",
    "            # Identify x and y values of those pixels\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "            # Define a bounding box based on min/max x and y\n",
    "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "            # Draw the box on the image\n",
    "            cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "        # Return the image\n",
    "        return img        \n",
    "\n",
    "    def get_boxes(self, labels):\n",
    "        boxes = []\n",
    "        for car_number in range(1, labels[1]+1):\n",
    "            # Find pixels with each car_number label value\n",
    "            nonzero = (labels[0] == car_number).nonzero()\n",
    "            # Identify x and y values of those pixels\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "            # Define a bounding box based on min/max x and y\n",
    "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "            boxes.append(bbox)\n",
    "\n",
    "        return boxes\n",
    "    \n",
    "    def add_heat(self, heatmap, bbox_list):\n",
    "        # Iterate through list of bboxes\n",
    "        for box in bbox_list:\n",
    "            # Add += 1 for all pixels inside each bbox\n",
    "            # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "            heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "            \n",
    "        return heatmap\n",
    "\n",
    "\n",
    "    def apply_threshold(self, heatmap, threshold):\n",
    "        # Zero out pixels below the threshold\n",
    "        heatmap[heatmap <= threshold] = 0\n",
    "        # Return thresholded map\n",
    "        return heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Car:\n",
    "    def __init__(self,position):\n",
    "        self.position = position\n",
    "        self.new_postion = None\n",
    "        self.count = 0\n",
    "        self.frame = 1\n",
    "        self.flag = False\n",
    "        self.long_count = 0\n",
    "        self.postion_average = []\n",
    "        \n",
    "    def update(self,temp_position):\n",
    "        if abs(temp_position[2]-self.position[2]) < 100 and abs(temp_position[3]-self.position[3]) < 100:\n",
    "            if self.long_count > 2:\n",
    "                self.postion_average.pop(0)\n",
    "                self.postion_average.append(temp_position)\n",
    "                self.new_postion = np.mean(np.array(self.postion_average), axis=0).astype(int)\n",
    "                self.position = self.new_postion\n",
    "                self.frame = 1\n",
    "                self.count += 1\n",
    "\n",
    "                return False\n",
    "\n",
    "            self.position = temp_position\n",
    "            self.postion_average.append(temp_position)\n",
    "            self.count+=1\n",
    "\n",
    "            return False        \n",
    "\n",
    "    def get_position(self):\n",
    "        self.frame+=1\n",
    "        if self.count == 7 and self.long_count < 3 :\n",
    "            self.new_postion = np.mean(np.array(self.postion_average), axis=0).astype(int)\n",
    "            self.count = 0\n",
    "            self.frame = 1\n",
    "            self.long_count += 1\n",
    "            if self.long_count < 2:\n",
    "                self.postion_average = []\n",
    "\n",
    "        if self.frame > 10:\n",
    "            self.flag = True\n",
    "\n",
    "        return self.new_postion, self.flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "train = False\n",
    "\n",
    "\n",
    "#Step 1. Train the model\n",
    "clf = CFClassifier()\n",
    "\n",
    "clf.spatial_size = (32, 32)\n",
    "clf.nbins = 32\n",
    "clf.hog_channels = \n",
    "\n",
    "car_images = glob.glob(\"../trainingdata/vehicles/*/*.png\")\n",
    "noncar_images = glob.glob(\"../trainingdata/non-vehicles/*/*.png\")\n",
    "\n",
    "training_data = (car_images, noncar_images)\n",
    "\n",
    "score = clf.train(training_data, visualise=False)\n",
    "print(\"Training score \", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Step 2. Finder\n",
    "clf = CFClassifier(unpickle=True)\n",
    "finder = CFCarFinder(clf)\n",
    "testImage = cv2.cvtColor(cv2.imread(\"./test_images/test5.jpg\"), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# testImage = cv2.cvtColor(cv2.imread(\"./car_notcar/image16.png\"), cv2.COLOR_BGR2YCrCb)\n",
    "# clf.process_image(testImage, visualise=True)\n",
    "\n",
    "#finder.findcar(testImage, draw_boxes=True)\n",
    "boxes = finder.findcar_with_subsampling(testImage, scale=1.0)\n",
    "labels = finder.get_labels(testImage, boxes, threshold = 12)\n",
    "#print(labels)\n",
    "finder.draw_labeles(testImage, labels)\n",
    "# for box in boxes:\n",
    "#     (x1, y1, x2, y2) = box[0][0], box[0][1], box[1][0], box[1][1]\n",
    "#     cv2.rectangle(testImage, (x1, y1), (x2, y2), (0, 0, 255), thickness=6)\n",
    "    \n",
    "plt.imshow(testImage)\n",
    "#plt.subplot(122).imshow(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_out.mp4\n",
      "[MoviePy] Writing video project_out.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [44:38<00:02,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_out.mp4 \n",
      "\n",
      "CPU times: user 44min 18s, sys: 30.4 s, total: 44min 49s\n",
      "Wall time: 44min 38s\n"
     ]
    }
   ],
   "source": [
    "#Step 3. Video Processing\n",
    "\n",
    "clf = CFClassifier(unpickle=True)\n",
    "finder = CFCarFinder(clf)\n",
    "\n",
    "counter = 0\n",
    "labels = None\n",
    "cars = []\n",
    "hot_windows=[]\n",
    "\n",
    "# Takes in a list of calculated centroids calculated from current frame from your own code  (both good and bad)\n",
    "\n",
    "def process_video_frame2(img):\n",
    "    global cars\n",
    "#     global counter\n",
    "#     global labels\n",
    "   \n",
    "#     if (counter % 5) != 0:\n",
    "#         counter+=1\n",
    "#         return img\n",
    "    \n",
    "#     counter+=1\n",
    "    boxes = finder.get_boxes(finder.findcar_with_subsampling(img, scale=1))\n",
    "    \n",
    "    # Deal with car tracking\n",
    "    for bbox in boxes:\n",
    "        centroid = (bbox[0][0],bbox[0][1], bbox[1][0], bbox[1][1])\n",
    "        new = True\n",
    "        for car in cars:\n",
    "            new = car.update(centroid)\n",
    "            if new == False:\n",
    "                break\n",
    "        if new == True:\n",
    "            cars.append(Car(centroid))\n",
    "\n",
    "    next_cars = []\n",
    "    positions = []\n",
    "\n",
    "    for car in cars:\n",
    "        position, flag = car.get_position()\n",
    "        if flag == False:\n",
    "            next_cars.append(car)\n",
    "        positions.append(position)\n",
    "\n",
    "    cars = next_cars\n",
    "\n",
    "    # Outputs current relevant positions.\n",
    "\n",
    "    try:\n",
    "        for (x1, y1, x2, y2) in positions:\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), thickness=2)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return img\n",
    "\n",
    "def process_video_frame(img):\n",
    "    global counter\n",
    "    global hot_windows\n",
    "    global labels\n",
    "\n",
    "    #if (counter % 3) == 0:\n",
    "    windows = finder.findcar_with_subsampling(img)\n",
    "    hot_windows.extend(windows)\n",
    "        \n",
    "    if (counter % 10) == 0:\n",
    "        labels = finder.get_labels(img, hot_windows, threshold=120)\n",
    "        hot_windows=[]\n",
    "        \n",
    "    counter+=1\n",
    "\n",
    "    if labels is not None and counter >= 10:\n",
    "        return finder.draw_labeles(img, labels)\n",
    "    else:\n",
    "        return img\n",
    "            \n",
    "\n",
    "video_out = 'project_out.mp4'\n",
    "clip = VideoFileClip(\"project_video.mp4\")\n",
    "out_clip = clip.fl_image(process_video_frame)\n",
    "%time out_clip.write_videofile(video_out, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 1\n",
    "clf = CFClassifier(unpickle=True)\n",
    "finder = CFCarFinder(clf)\n",
    "\n",
    "def processthis(img):\n",
    "    global count\n",
    "    cv2.imwrite(\"./output_images/{0}frame.png\".format(count), cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    count+=1\n",
    "    return img\n",
    "\n",
    "video = VideoFileClip(\"project_video.mp4\")\n",
    "img = video.get_frame(40)\n",
    "\n",
    "boxes = finder.findcar_with_subsampling(img, scale=1)\n",
    "labels = finder.get_labels(img, boxes, threshold = 24)\n",
    "finder.draw_labeles(img, labels)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
